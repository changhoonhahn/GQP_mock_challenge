{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.stats import norm as Norm\n",
    "from pymc3 import Model, sample, Normal, Uniform, model_to_graphviz, plot_posterior, trace_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- plotting --\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt \n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "mpl.rcParams['axes.linewidth'] = 1.5\n",
    "mpl.rcParams['axes.xmargin'] = 1\n",
    "mpl.rcParams['xtick.labelsize'] = 'x-large'\n",
    "mpl.rcParams['xtick.major.size'] = 5\n",
    "mpl.rcParams['xtick.major.width'] = 1.5\n",
    "mpl.rcParams['ytick.labelsize'] = 'x-large'\n",
    "mpl.rcParams['ytick.major.size'] = 5\n",
    "mpl.rcParams['ytick.major.width'] = 1.5\n",
    "mpl.rcParams['legend.frameon'] = False\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hyper = np.array([0., 1.]) # mean and variance of the true population\n",
    "mu_dist = Norm(loc=theta_hyper[0], scale=theta_hyper[1])\n",
    "mu_samp = mu_dist.rvs(size=1000)\n",
    "\n",
    "# add some noise\n",
    "alpha = 1. \n",
    "xs = mu_samp + alpha * np.random.normal(size=len(mu_samp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toy example where we have some physical parameter $\\mu$ that comes from a Gaussian distribution defined by hyperparameters $\\theta = \\{\\theta_\\mu, \\theta_\\sigma\\}$. \n",
    "$$\\mu \\sim \\mathcal{N}(\\theta_\\mu, \\theta_\\sigma)$$\n",
    "Of course, we don't directly observe $\\mu$. We observe $x$, which in the toy example will just be a noisy measurement of $\\mu$. \n",
    "$$x \\sim \\mathcal{N}(\\mu, \\alpha = 1.)$$\n",
    "In a more realistic example, $\\mu$ can be $M_*$ and $\\theta$ can be Schecter function parameters. $x$ would in that case be a galaxy spectrum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "This function requires the python library graphviz, along with binaries. The easiest way to install all of this is by running\n\n\tconda install -c conda-forge python-graphviz",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pymc3/model_graph.py\u001b[0m in \u001b[0;36mmake_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c0e49ab9647d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel_to_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_pooling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pymc3/model_graph.py\u001b[0m in \u001b[0;36mmodel_to_graphviz\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \"\"\"\n\u001b[1;32m    195\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mModelGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pymc3/model_graph.py\u001b[0m in \u001b[0;36mmake_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             raise ImportError('This function requires the python library graphviz, along with binaries. '\n\u001b[0m\u001b[1;32m    160\u001b[0m                               \u001b[0;34m'The easiest way to install all of this is by running\\n\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                               '\\tconda install -c conda-forge python-graphviz')\n",
      "\u001b[0;31mImportError\u001b[0m: This function requires the python library graphviz, along with binaries. The easiest way to install all of this is by running\n\n\tconda install -c conda-forge python-graphviz"
     ]
    }
   ],
   "source": [
    "with Model() as partial_pooling:\n",
    "\n",
    "    # Priors\n",
    "    theta_mu = Uniform('theta_mu', lower=-5., upper=5.)\n",
    "    theta_sig = Uniform('theta_sigma', lower=0., upper=2.)\n",
    "\n",
    "    # Random intercepts\n",
    "    mu = Normal('mu', mu=theta_mu, sigma=theta_sig, shape=1000)\n",
    "\n",
    "    # Model error\n",
    "    #alpha = 1.#Uniform('alpha', lower=0.5, upper=1.5)\n",
    "\n",
    "    # Data likelihood\n",
    "    x = Normal('x', mu=mu, sigma=alpha, observed=xs)\n",
    "\n",
    "model_to_graphviz(partial_pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "sub = fig.add_subplot(111)\n",
    "sub.hist(mu_samp, bins=20, density=True, color='C0', alpha=0.5)\n",
    "sub.plot(np.linspace(-10., 10, 100), mu_dist.pdf(np.linspace(-10., 10, 100)))\n",
    "sub.set_xlabel('$\\mu$', fontsize=20)\n",
    "sub.set_xlim(-5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the most general case, we'll the posterior $p(\\mu_i | x_i)$ for each object. In the realistic case, this will be the posteriors $p(M_*|{\\rm spectrum})$. \n",
    "\n",
    "In our toy example, since $x \\sim \\mathcal{N}(\\mu, \\alpha = 1.)$, $p(\\mu_i | x_i)$ is just a Gaussian of width $\\alpha$ centered around $x_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_post = np.zeros((len(xs), 100)) \n",
    "for i, x in enumerate(xs): \n",
    "    _norm = Norm(loc=x, scale=alpha)\n",
    "    mu_post[i,:] = _norm.rvs(size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "sub = fig.add_subplot(111)\n",
    "for i in range(5): \n",
    "    sub.hist(mu_post[i,:], bins=20, density=True, alpha=0.25)\n",
    "#sub.hist(mu_samp, bins=20, density=True, color='C0', alpha=0.5)\n",
    "sub.plot(np.linspace(-10., 10, 100), mu_dist.pdf(np.linspace(-10., 10, 100)))\n",
    "sub.set_xlabel('$\\mu$', fontsize=20)\n",
    "sub.set_xlim(-5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what happens if we do what is typically done --- i.e. treating the median of the posterior as point estimates of $\\mu$. This is equivalent to taking the median of each posterior $p(\\mu_i|x_i)$. Here's how the PDF of $\\mu$ looks with this *incorrect* method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "sub = fig.add_subplot(111)\n",
    "sub.hist(np.median(mu_post, axis=1), bins=20, density=True, color='C1', alpha=0.5)\n",
    "sub.plot(np.linspace(-10., 10, 100), mu_dist.pdf(np.linspace(-10., 10, 100)))\n",
    "sub.set_xlim([-5, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets be more qualitative, how does this impact the posteriors of hyperpameters $\\theta_\\mu$ and $\\theta_\\sigma$, which is what we're ultimately interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "import corner\n",
    "mu_pt = np.median(mu_post, axis=1)\n",
    "\n",
    "def lnprior(tt): \n",
    "    tt0, tt1 = tt\n",
    "    if (-10. < tt0 < 10.) and (0. < tt1 < 2.): \n",
    "        return 0. \n",
    "    return -np.inf\n",
    "\n",
    "def lnlike(tt): \n",
    "    return -0.5 * np.sum((tt[0] - mu_pt)**2)/tt[1]**2 - (float(len(mu_pt)) * np.log(tt[1]))\n",
    "\n",
    "def lnprob(tt): \n",
    "    lp = lnprior(tt)\n",
    "    if not np.isfinite(lp): \n",
    "        return -np.inf\n",
    "    return lp + lnlike(tt)\n",
    "\n",
    "ndim, nwalkers = 2, 100\n",
    "pos = [np.array([0., 1.]) + 1e-4*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob)\n",
    "sampler.run_mcmc(pos, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sampler.chain[:, 50:, :].reshape((-1, ndim))\n",
    "import corner\n",
    "fig = corner.corner(samples, labels=[r\"$\\theta_\\mu$\", r\"$\\theta_\\sigma$\"], label_kwargs={'fontsize': 25}, truths=[0., 1.], range=[(-0.5, 0.5), (0.5, 1.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we can use hierarchical bayesian models to infer the posteriors of $\\theta_\\mu$ and $\\theta_\\sigma$ given $\\{x_i\\}$. \n",
    "$$p(\\theta|\\{x_i\\}) \\propto p(\\{x_i\\}|\\theta) p(\\theta)$$\n",
    "where the likelihood of the hyperparameters can be written \n",
    "$$p(\\{x_i\\} | \\theta) = p(\\{x_i\\} | \\alpha)\\int \\frac{p(\\{\\mu_i\\}|\\theta)}{p(\\{\\mu_i\\}|\\alpha)} p(\\{\\mu_i\\}|\\{x_i\\}, \\alpha) d\\{\\mu_i\\}$$\n",
    "\n",
    "In our toy example this is, I think \n",
    "$$p(\\{x_i\\} | \\theta) = \\int p(\\{\\mu_i\\}|\\theta) p(\\{\\mu_i\\}|\\{x_i\\}, \\alpha) d\\{\\mu_i\\}$$\n",
    "The integration can be evaluated using importance sampling \n",
    "$$p(\\{x_i\\} | \\theta) = \\sum\\limits_{\\{\\mu_i\\}^{(n)}; n=1}^{N} p(\\{\\mu_i\\}^{(n)}|\\theta)$$\n",
    "where $\\{\\mu_i\\}^{(n)}$ is sampled from the posterior $p(\\{\\mu_i\\} | \\{x_i\\})$. \n",
    "\n",
    "For this toy example it's easy to use pymc to sample everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with partial_pooling:\n",
    "    partial_pooling_trace = sample(1000, tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdm_samples = np.array([partial_pooling_trace['theta_mu'], partial_pooling_trace['theta_sigma']]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = corner.corner(hdm_samples, labels=[r\"$\\theta_\\mu$\", r\"$\\theta_\\sigma$\"], label_kwargs={'fontsize': 25}, truths=[0., 1.], range=[(-0.5, 0.5), (0.5, 1.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
